!obj:pylearn2.train.Train {
 dataset: !obj:pylearn2.datasets.csv_dataset.CSVDataset &train {
  path: '/home/dean/git/kaggle/forest_cover/train_mlp.csv',
  one_hot: 1
 },
 model: !obj:pylearn2.models.mlp.MLP {
  layers: [
   !obj:pylearn2.models.mlp.PretrainedLayer {
    layer_name: 'h1',
    layer_content: !pkl: "./dae_l1.pkl"
   },
   !obj:pylearn2.models.mlp.PretrainedLayer {
    layer_name: 'h2',
    layer_content: !pkl: "./dae_l2.pkl"
   },
   !obj:pylearn2.models.mlp.PretrainedLayer {
    layer_name: 'h3',
    layer_content: !pkl: "./dae_l3.pkl"
   },
   !obj:pylearn2.models.mlp.Softmax {
    layer_name: 'y',
    n_classes: 7,
    irange: .005
   }
  ],
  nvis: 103
 },
 algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
  batch_size: 50,
  learning_rate: .05,
  monitoring_dataset: {
   'train': *train,
   'valid': !obj:pylearn2.datasets.csv_dataset.CSVDataset {
    path: '/home/dean/git/kaggle/forest_cover/valid_mlp.csv',
    one_hot: 1
   },
   'test': !obj:pylearn2.datasets.csv_dataset.CSVDataset {
    path: '/home/dean/git/kaggle/forest_cover/test_mlp.csv',
    one_hot: 1
   }
  },
  cost: !obj:pylearn2.costs.mlp.Default {},
  learning_rule: !obj:pylearn2.training_algorithms.learning_rule.Momentum {
   init_momentum : .5
  },
  termination_criterion: !obj:pylearn2.termination_criteria.And {
   criteria: [
    !obj:pylearn2.termination_criteria.MonitorBased {
     channel_name: "valid_y_misclass",
     prop_decrease: 0.,
     N: 100
    },
    !obj:pylearn2.termination_criteria.EpochCounter {
     max_epochs: 10000
    }
   ]
  },
  update_callbacks: !obj:pylearn2.training_algorithms.sgd.ExponentialDecay {
   decay_factor: 1.00004,
   min_lr: .000001
  }
 },
 extensions: [
  !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
   channel_name: "valid_y_misclass",
   save_path: "dae.pkl"
  },
  !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {
   start: 1,
   saturate: 10,
   final_momentum: .7
  }
 ]
}